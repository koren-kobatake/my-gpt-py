import os
import json
from datetime import datetime
import gradio as gr
from dotenv import load_dotenv
from openai import OpenAI

# .envã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
CHAT_HISTORY_DIR = "chat_histories"
MARKDOWN_EXPORT_DIR = "markdown_exports"
os.makedirs(CHAT_HISTORY_DIR, exist_ok=True)
os.makedirs(MARKDOWN_EXPORT_DIR, exist_ok=True)

# æœ€æ–°ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã¨ç‰¹å¾´ï¼ˆ2025å¹´7æœˆæ™‚ç‚¹ï¼‰
MODEL_INFO = {
    "chatgpt-4o-latest": "chatgpt-4o-latest: GPT-4oã®æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«è‡ªå‹•æ›´æ–°ã•ã‚Œã‚‹å‹•çš„ãƒ¢ãƒ‡ãƒ«ã€‚OpenAIã®æœ€æ–°ç ”ç©¶æˆæœã‚’åæ˜ ã€‚APIã§ã®ç ”ç©¶ãƒ»è©•ä¾¡ã‚„ã€å¸¸ã«æœ€æ–°ã®æ€§èƒ½ã‚’ä½“é¨“ã—ãŸã„ç”¨é€”ã«æœ€é©ã€‚å®Ÿé‹ç”¨ã«ã¯æ—¥ä»˜æŒ‡å®šãƒ¢ãƒ‡ãƒ«æ¨å¥¨ã€‚",
    # "gpt-4.5": "GPT-4.5: æ„Ÿæƒ…ç†è§£ãƒ»å‰µé€ æ€§ãƒ»è‡ªç„¶ãªå¯¾è©±ã«å„ªã‚Œã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ãŒå¤§å¹…æ¸›å°‘ã€‚é«˜å“è³ªãªæ–‡ç« ç”Ÿæˆã‚„å‰µé€ çš„ã‚¿ã‚¹ã‚¯ã«æœ€é©ã€‚",
    "gpt-4.1": "GPT-4.1: é•·æ–‡è„ˆå‡¦ç†ãƒ»é«˜é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ»ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°èƒ½åŠ›å‘ä¸Šã€‚é•·æ–‡è§£æã‚„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æ”¯æ´ã«æœ€é©ã€‚",
    "gpt-4.1-mini": "GPT-4.1 mini: é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆã€‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¿œç­”ã‚„ã‚³ã‚¹ãƒˆé‡è¦–ã®æ¥­å‹™è‡ªå‹•åŒ–ã«æœ€é©ã€‚",
    "gpt-4.1-nano": "GPT-4.1 nano: è¶…è»½é‡ãƒ¢ãƒ‡ãƒ«ã€‚ã‚³ã‚¹ãƒˆãƒ»é€Ÿåº¦é‡è¦–ã®ç”¨é€”å‘ã‘ã€‚",
    "gpt-4o": "GPT-4o: ãƒ†ã‚­ã‚¹ãƒˆãƒ»ç”»åƒãƒ»éŸ³å£°ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«AIã‚¢ãƒ—ãƒªã‚„ç”»åƒï¼‹ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã«æœ€é©ã€‚",
    "gpt-4o-mini": "GPT-4o mini: GPT-4oã®è»½é‡ç‰ˆã€‚æ—¥å¸¸çš„ãªãƒãƒ£ãƒƒãƒˆã‚„è»½é‡ã‚¢ãƒ—ãƒªå‘ã‘ã€‚",
    # "o3": "o3: é«˜åº¦ãªæ¨è«–èƒ½åŠ›ã€‚æ•°å­¦ãƒ»ç§‘å­¦ãƒ»è¤‡é›‘ãªæ„æ€æ±ºå®šã«å¼·ã„ã€‚",
    # "o3-pro": "o3-pro: o3ã®é«˜ä¿¡é ¼æ€§ç‰ˆã€‚é‡è¦ãªæ„æ€æ±ºå®šã‚„è¤‡é›‘ãªæ¨è«–ã«ã€‚",
    "o4-mini": "o4-mini: oã‚·ãƒªãƒ¼ã‚ºã®æœ€æ–°æ¨è«–ç‰¹åŒ–å‹ã€‚æ—¥å¸¸æ¥­å‹™ã®è‡ªå‹•åŒ–ã‚„ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã‚¿ã‚¹ã‚¯ã«ã€‚",
    "o4-mini-high": "o4-mini-high: o4-miniã®é«˜ç²¾åº¦ãƒ»é«˜ä¿¡é ¼æ€§ç‰ˆã€‚ãƒŸãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªæ¨è«–ã‚„è¤‡é›‘ãªæ¥­å‹™ã«ã€‚",
    "o1": "o1: å¼·åŒ–å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®æ¨è«–ãƒ¢ãƒ‡ãƒ«ã€‚ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚„æ®µéšçš„ãªæ¨è«–ãŒå¿…è¦ãªæŠ€è¡“ã‚¿ã‚¹ã‚¯ã«ã€‚",
}

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
def get_history_path(user_id):
    return os.path.join(CHAT_HISTORY_DIR, f"{user_id}.json")

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´èª­ã¿è¾¼ã¿
def load_history(user_id):
    path = get_history_path(user_id)
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ä¿å­˜
def save_history(user_id, history):
    path = get_history_path(user_id)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

# ChatGPTå‘ã‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã¸å¤‰æ›
def build_messages_from_history(history, latest_user_message):
    messages = [{"role": h["role"], "content": h["content"]}
                for h in history if h["role"] in ["user", "assistant"]]
    messages.append({"role": "user", "content": latest_user_message})
    return messages[-10:]

# ChatGPT ã«å•ã„åˆã‚ã›ï¼ˆãƒ¢ãƒ‡ãƒ«ã‚’å¼•æ•°åŒ–ï¼‰
def chatbot_response(message, full_history, user_id, model_name):
    messages = build_messages_from_history(full_history, message)
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=messages
        )
        reply = response.choices[0].message.content
    except Exception as e:
        reply = f"âš ï¸ APIã‚¨ãƒ©ãƒ¼: {e}"

    # å±¥æ­´ã«ä¿å­˜
    full_history.append({"role": "user", "content": message, "timestamp": datetime.now().isoformat()})
    full_history.append({"role": "assistant", "content": reply, "timestamp": datetime.now().isoformat()})
    save_history(user_id, full_history)

    return reply, full_history

# æœ€æ–°ã®è³ªå•ã¨å›ç­”ã®ã¿Markdownå‡ºåŠ›
def export_latest_to_markdown(user_id, history):
    if not history or len(history) < 2:
        return "âš ï¸ å‡ºåŠ›ã™ã‚‹å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“"

    latest_assistant_idx = len(history) - 1
    latest_user_idx = latest_assistant_idx - 1

    if history[latest_assistant_idx]["role"] != "assistant":
        return "âš ï¸ æœ€æ–°ãŒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã§ã¯ã‚ã‚Šã¾ã›ã‚“"

    question = history[latest_user_idx]["content"] if history[latest_user_idx]["role"] == "user" else "ï¼ˆè³ªå•ãªã—ï¼‰"
    answer = history[latest_assistant_idx]["content"]
    timestamp = history[latest_assistant_idx].get("timestamp", datetime.now().isoformat())
    safe_time = timestamp.replace(":", "-").replace(".", "-")
    filename = f"{user_id}_{safe_time}.md"
    path = os.path.join(MARKDOWN_EXPORT_DIR, filename)

    with open(path, "w", encoding="utf-8") as f:
        f.write(f"# è³ªå•\n\n{question}\n\n# å›ç­”\n\n{answer}")

    return f"âœ… Markdownå‡ºåŠ›å®Œäº†: {filename}"

# Gradio ã‚¢ãƒ—ãƒª
with gr.Blocks() as app:
    gr.Markdown("# ChatGPTï¼ˆæœ€æ–°ã®è³ªå•ï¼†å›ç­”ã®ã¿Markdownä¿å­˜ï¼‰")

    user_id = gr.Textbox(label="ãƒ¦ãƒ¼ã‚¶ãƒ¼ID", placeholder="ä¾‹: user_xyz")

    model_selector = gr.Dropdown(
        choices=list(MODEL_INFO.keys()),
        value="chatgpt-4o-latest",
        label="ãƒ¢ãƒ‡ãƒ«é¸æŠ"
    )

    # ãƒ¢ãƒ‡ãƒ«ã®ç”¨é€”ã‚’è¡¨ç¤º
    model_info_display = gr.Markdown(MODEL_INFO["chatgpt-4o-latest"])

    chatbot = gr.Chatbot(label="ãƒãƒ£ãƒƒãƒˆ", type="messages")
    msg = gr.Textbox(label="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›")
    clear = gr.Button("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢")
    state = gr.State([])  # ãƒãƒ£ãƒƒãƒˆå±¥æ­´
    output_status = gr.Textbox(label="å‡ºåŠ›ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", interactive=False)
    export_button = gr.Button("ğŸ“ æœ€æ–°ã®å›ç­”ã‚’Markdownä¿å­˜")

    # Gradioç”¨ãƒãƒ£ãƒƒãƒˆå½¢å¼ã«å¤‰æ›
    def update_chatbot_display(history):
        return [{"role": h["role"], "content": h["content"]}
                for h in history if h["role"] in ["user", "assistant"]]

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡å‡¦ç†
    def user_submit(user_message, history, user_id, model_name):
        if not user_id.strip():
            history.append({"role": "assistant", "content": "âš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"})
            return "", history, update_chatbot_display(history)

        history = history if history else load_history(user_id)
        reply, new_history = chatbot_response(user_message, history, user_id, model_name)
        return "", new_history, update_chatbot_display(new_history)

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚¯ãƒªã‚¢
    def clear_session(user_id):
        path = get_history_path(user_id)
        if os.path.exists(path):
            os.remove(path)
        return [], "", [], ""

    # Markdownå‡ºåŠ›ãƒœã‚¿ãƒ³å‡¦ç†
    def export_markdown(user_id, history):
        return export_latest_to_markdown(user_id, history)

    # ãƒ¢ãƒ‡ãƒ«å¤‰æ›´æ™‚ã®èª¬æ˜æ›´æ–°
    def update_model_info(selected_model):
        return MODEL_INFO.get(selected_model, "")

    # ã‚¤ãƒ™ãƒ³ãƒˆè¨­å®š
    msg.submit(
        fn=user_submit,
        inputs=[msg, state, user_id, model_selector],
        outputs=[msg, state, chatbot]
    )

    clear.click(
        fn=clear_session,
        inputs=user_id,
        outputs=[state, msg, chatbot, output_status]
    )

    export_button.click(
        fn=export_markdown,
        inputs=[user_id, state],
        outputs=output_status
    )

    model_selector.change(
        fn=update_model_info,
        inputs=[model_selector],
        outputs=model_info_display
    )

app.launch(server_port=8510)
