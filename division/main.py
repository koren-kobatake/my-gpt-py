import os
import json
from datetime import datetime
import gradio as gr
from dotenv import load_dotenv
from openai import OpenAI
import fastapi

# .envã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

CHAT_HISTORY_DIR = "chat_histories"
MARKDOWN_EXPORT_DIR = "markdown_exports"
os.makedirs(CHAT_HISTORY_DIR, exist_ok=True)
os.makedirs(MARKDOWN_EXPORT_DIR, exist_ok=True)

MODEL_INFO = {
    "chatgpt-4o-latest": "chatgpt-4o-latest: GPT-4oã®æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«è‡ªå‹•æ›´æ–°ã•ã‚Œã‚‹å‹•çš„ãƒ¢ãƒ‡ãƒ«ã€‚",
    "gpt-4.1": "GPT-4.1: é•·æ–‡è„ˆå‡¦ç†ãƒ»é«˜é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ»ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°èƒ½åŠ›å‘ä¸Šã€‚",
    "gpt-4.1-mini": "GPT-4.1 mini: é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆã€‚",
    "gpt-4.1-nano": "GPT-4.1 nano: è¶…è»½é‡ãƒ¢ãƒ‡ãƒ«ã€‚",
    "gpt-4o": "GPT-4o: ãƒ†ã‚­ã‚¹ãƒˆãƒ»ç”»åƒãƒ»éŸ³å£°ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œã€‚",
    "gpt-4o-mini": "GPT-4o mini: GPT-4oã®è»½é‡ç‰ˆã€‚",
    "o4-mini": "o4-mini: oã‚·ãƒªãƒ¼ã‚ºã®æœ€æ–°æ¨è«–ç‰¹åŒ–å‹ã€‚",
    "o4-mini-high": "o4-mini-high: o4-miniã®é«˜ç²¾åº¦ãƒ»é«˜ä¿¡é ¼æ€§ç‰ˆã€‚",
    "o1": "o1: å¼·åŒ–å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®æ¨è«–ãƒ¢ãƒ‡ãƒ«ã€‚"
}

def get_history_path(chat_id):
    return os.path.join(CHAT_HISTORY_DIR, f"{chat_id}.json")

def load_history(chat_id):
    path = get_history_path(chat_id)
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_history(chat_id, history):
    path = get_history_path(chat_id)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

def build_messages_from_history(history, latest_user_message):
    messages = [{"role": h["role"], "content": h["content"]}
                for h in history if h["role"] in ["user", "assistant"]]
    messages.append({"role": "user", "content": latest_user_message})
    return messages[-10:]

def chatbot_response(message, full_history, chat_id, model_name, save=False):
    messages = build_messages_from_history(full_history, message)
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=messages
        )
        reply = response.choices[0].message.content
    except Exception as e:
        reply = f"âš ï¸ APIã‚¨ãƒ©ãƒ¼: {e}"

    full_history.append({"role": "user", "content": message, "timestamp": datetime.now().isoformat()})
    full_history.append({"role": "assistant", "content": reply, "timestamp": datetime.now().isoformat()})

    if save and chat_id:
        save_history(chat_id, full_history)

    return reply, full_history

def export_latest_to_markdown(chat_id, history):
    if not history or len(history) < 2:
        return "âš ï¸ å‡ºåŠ›ã™ã‚‹å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“"

    latest_assistant_idx = len(history) - 1
    latest_chat_idx = latest_assistant_idx - 1

    if history[latest_assistant_idx]["role"] != "assistant":
        return "âš ï¸ æœ€æ–°ãŒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã§ã¯ã‚ã‚Šã¾ã›ã‚“"

    question = history[latest_chat_idx]["content"] if history[latest_chat_idx]["role"] == "user" else "ï¼ˆè³ªå•ãªã—ï¼‰"
    answer = history[latest_assistant_idx]["content"]
    timestamp = history[latest_assistant_idx].get("timestamp", datetime.now().isoformat())
    safe_time = timestamp.replace(":", "-").replace(".", "-")
    filename = f"{chat_id}_{safe_time}.md"
    path = os.path.join(MARKDOWN_EXPORT_DIR, filename)

    with open(path, "w", encoding="utf-8") as f:
        f.write(f"# è³ªå•\n\n{question}\n\n# å›ç­”\n\n{answer}")

    return f"âœ… Markdownå‡ºåŠ›å®Œäº†: {filename}"

def get_existing_chat_ids():
    return [f.replace(".json", "") for f in os.listdir(CHAT_HISTORY_DIR) if f.endswith(".json")]

def update_chatbot_display(history):
    return [{"role": h["role"], "content": h["content"]}
            for h in history if h["role"] in ["user", "assistant"]]

def get_chat_id(text_input, dropdown_input, mode):
    return text_input.strip() if mode == "æ–°è¦å…¥åŠ›" else dropdown_input

with gr.Blocks() as app:
    gr.Markdown("## ğŸ§  ChatGPT Markdownå‡ºåŠ›å¯¾å¿œã‚¢ãƒ—ãƒª")

    with gr.Row():
        # å·¦ãƒšã‚¤ãƒ³
        with gr.Column(scale=1):
            save_mode = gr.Radio(["å±¥æ­´ã‚’æ®‹ã™", "å±¥æ­´ã‚’æ®‹ã•ãªã„"], value="å±¥æ­´ã‚’æ®‹ã™", label="å±¥æ­´ä¿å­˜ãƒ¢ãƒ¼ãƒ‰")

            chat_id_mode = gr.Radio(["æ–°è¦å…¥åŠ›", "æ—¢å­˜ã‹ã‚‰é¸æŠ"], value="æ–°è¦å…¥åŠ›", label="ãƒãƒ£ãƒƒãƒˆIDã®æŒ‡å®šæ–¹æ³•")

            chat_id_text = gr.Textbox(label="ãƒãƒ£ãƒƒãƒˆIDï¼ˆæ–°è¦ï¼‰", placeholder="ä¾‹: user_abc", visible=True)
            chat_id_dropdown = gr.Dropdown(choices=get_existing_chat_ids(), label="ãƒãƒ£ãƒƒãƒˆIDï¼ˆæ—¢å­˜ï¼‰", visible=False)

            model_selector = gr.Dropdown(choices=list(MODEL_INFO.keys()), value="chatgpt-4o-latest", label="ãƒ¢ãƒ‡ãƒ«é¸æŠ")
            model_info_display = gr.Markdown(MODEL_INFO["chatgpt-4o-latest"])

        # å³ãƒšã‚¤ãƒ³
        with gr.Column(scale=3):
            chatbot = gr.Chatbot(label="ãƒãƒ£ãƒƒãƒˆ", type="messages")
            msg = gr.Textbox(label="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›")
            with gr.Row():
                clear = gr.Button("ğŸ§¹ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚¯ãƒªã‚¢")
                export_button = gr.Button("ğŸ“ Markdownä¿å­˜")
            output_status = gr.Textbox(label="å‡ºåŠ›ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", interactive=False)

    state = gr.State([])

    def toggle_chat_id_inputs(mode):
        return (
            gr.update(visible=(mode == "æ–°è¦å…¥åŠ›")),
            gr.update(visible=(mode == "æ—¢å­˜ã‹ã‚‰é¸æŠ"))
        )

    chat_id_mode.change(fn=toggle_chat_id_inputs, inputs=[chat_id_mode], outputs=[chat_id_text, chat_id_dropdown])

    def on_select_existing_chat_id(selected_id):
        history = load_history(selected_id) if selected_id else []
        return history, update_chatbot_display(history)

    chat_id_dropdown.change(fn=on_select_existing_chat_id, inputs=chat_id_dropdown, outputs=[state, chatbot])

    def user_submit(user_message, history, chat_id_text_val, chat_id_dropdown_val, chat_id_mode_val, model_name, save_option):
        save_enabled = (save_option == "å±¥æ­´ã‚’æ®‹ã™")
        current_id = get_chat_id(chat_id_text_val, chat_id_dropdown_val, chat_id_mode_val)

        if save_enabled and not current_id:
            history.append({"role": "assistant", "content": "âš ï¸ ãƒãƒ£ãƒƒãƒˆIDã‚’å…¥åŠ›ã¾ãŸã¯é¸æŠã—ã¦ãã ã•ã„"})
            return user_message, history, update_chatbot_display(history)

        if save_enabled and history == []:
            history = load_history(current_id)

        reply, updated_history = chatbot_response(user_message, history, current_id, model_name, save=save_enabled)
        return "", updated_history, update_chatbot_display(updated_history)

    msg.submit(
        fn=user_submit,
        inputs=[msg, state, chat_id_text, chat_id_dropdown, chat_id_mode, model_selector, save_mode],
        outputs=[msg, state, chatbot]
    )

    model_selector.change(fn=lambda selected: MODEL_INFO[selected], inputs=model_selector, outputs=model_info_display)

    def do_clear(chat_id_text_val, chat_id_dropdown_val, chat_id_mode_val):
        chat_id_val = get_chat_id(chat_id_text_val, chat_id_dropdown_val, chat_id_mode_val)
        if chat_id_val:
            path = get_history_path(chat_id_val)
            if os.path.exists(path):
                os.remove(path)
        return [], "", [], "âœ… ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ"

    clear.click(fn=do_clear, inputs=[chat_id_text, chat_id_dropdown, chat_id_mode],
                outputs=[state, msg, chatbot, output_status])

    def do_export(chat_id_text_val, chat_id_dropdown_val, chat_id_mode_val, history, save_option):
        if save_option != "å±¥æ­´ã‚’æ®‹ã™":
            return "âš ï¸ Markdownå‡ºåŠ›ã¯å±¥æ­´ä¿å­˜ãƒ¢ãƒ¼ãƒ‰ã®ã¿å¯¾å¿œã—ã¦ã„ã¾ã™"
        chat_id_val = get_chat_id(chat_id_text_val, chat_id_dropdown_val, chat_id_mode_val)
        if not chat_id_val:
            return "âš ï¸ ãƒãƒ£ãƒƒãƒˆIDãŒæœªæŒ‡å®šã§ã™"
        return export_latest_to_markdown(chat_id_val, history)

    export_button.click(fn=do_export,
                        inputs=[chat_id_text, chat_id_dropdown, chat_id_mode, state, save_mode],
                        outputs=output_status)

    # app.launch(debug=True, server_port=8520)
    app_api = fastapi.FastAPI()
    app_api = gr.mount_gradio_app(app_api, app, path="/gradio")